---
title: "DA 6813 Case Study 3 Dow Jones"
author: "Will Hyltin, Holly Milazzo and Tim Harrison"
date: today
format: 
  html:
    code-fold: true # Folds code by default
    number-sections: true # Numbered sections
    df-print: paged # Nice table format
    fig-align: center # Centers figures
    fig-width: 6 # Adjust figure size
    fig-height: 4
    reference-location: section # Valid value for citation references
    page-layout: article
---

# Executive Summary

This case study focuses on predicting weekly stock price changes for the Dow Jones Index to optimize investment strategies. Using historical stock performance data, including prices, trading volumes, and financial indicators, the analysis aimed to forecast the **percent_change_next_weeks_price** for each stock. Three models—Linear Regression (LM), Decision Trees (DT), and Support Vector Regression (SVR)—were developed and evaluated using Root Mean Square Error (RMSE) as the primary metric. Data preprocessing steps included handling missing values with KNN imputation and normalizing numeric features to ensure comparability, especially for SVR. The findings showed that SVR consistently outperformed LM and DT, delivering the lowest RMSE across various stocks. This highlights its superior capability in capturing complex, non-linear relationships within the data. The insights gained from this analysis provide actionable recommendations for selecting stocks with high growth potential and managing investment risks. Future enhancements, such as incorporating ensemble methods and additional financial indicators, could further improve predictive accuracy and decision-making.

# Problem Statement

The Dow Jones Index case study addresses a critical business challenge: predicting weekly stock performance to optimize investment strategies. In a highly volatile market, businesses and investors rely on accurate forecasts to maximize returns and mitigate risks. This study aims to develop predictive models that forecast the percentage change in stock prices for the following week, helping identify stocks with the highest growth potential. Using historical data, including stock prices, trading volumes, and financial indicators, the analysis seeks to improve decision-making by leveraging models such as Linear Regression, Decision Trees, and Support Vector Regression. These models will be evaluated for their accuracy and ability to assess risk using methods like the Capital Asset Pricing Model (CAPM). Addressing this problem will enable businesses to allocate resources more effectively, capitalize on profitable opportunities, and enhance their competitive edge in the financial market. Notably, the study will also examine broader market risks, such as the unusual losses experienced by all Dow Jones stocks in the week ending May 27, 2011, providing a comprehensive view of potential challenges.



# Additional Sources

Support Vector Machines (SVMs) have been extensively applied in financial markets for stock price prediction due to their ability to handle complex, non-linear relationships. For instance, a study by Kim (2003) demonstrated that SVMs could outperform traditional models in forecasting stock price indices, highlighting their robustness in capturing market dynamics. 

The Capital Asset Pricing Model (CAPM) is a fundamental tool in finance for assessing the risk and expected return of an investment. It establishes a linear relationship between the expected return of an asset and its systematic risk, measured by beta. This model aids investors in determining whether a stock is fairly priced relative to its risk. For a comprehensive understanding of CAPM, Investopedia provides an in-depth explanation of its components and applications. 

Integrating SVMs for stock price prediction with CAPM for risk assessment can offer a holistic approach to investment decision-making, combining advanced predictive analytics with established financial theories. 

1. **Kim, K. (2003).**  
   A study on the application of Support Vector Machines (SVM) for stock price index prediction.  
  https://www.researchgate.net/publication/220379019

2. **Wall Street Prep - Capital Asset Pricing Model (CAPM).**  
   Comprehensive guide on using CAPM for risk assessment in financial markets.  
   https://www.wallstreetprep.com/knowledge/capm-capital-asset-pricing-model

3. **Investopedia - Capital Asset Pricing Model (CAPM).**  
   In-depth explanation of CAPM, its components, and applications.  
  https://www.investopedia.com/terms/c/capm.asp


# Methodology

To predict weekly stock price changes (`percent_change_next_weeks_price`), we employed three models: Linear Regression (LM), Decision Trees (DT), and Support Vector Regression (SVR). Before modeling, we performed comprehensive data preprocessing. Missing values in key variables were addressed using KNN imputation to preserve data integrity. Numeric features were scaled and normalized to ensure comparability, particularly important for SVR, which relies on distance measures in feature space. Lagged variables were created to capture potential temporal dependencies; however, lagged plots indicated no significant relationship between the lagged variables and the target, so they were excluded from the final models. The data was then split into training (Q1) and testing (Q2) sets, maintaining temporal integrity to simulate real-world forecasting scenarios.

Each model comes with specific assumptions. Linear Regression assumes a linear relationship between predictors and the target, independence of errors, homoscedasticity (constant error variance), and normally distributed errors. It also requires minimal multicollinearity among predictors. Decision Trees, being non-parametric, do not assume a specific relationship between predictors and the target but are sensitive to small data changes. SVR, which emerged as the best-performing model, makes no assumptions about the data's underlying distribution but relies on normalized inputs to maximize the margin around the true values. Model performance was evaluated using Root Mean Square Error (RMSE), as it effectively measures prediction accuracy without the limitations of Mean Absolute Percentage Error (MAPE), which is problematic when actual values approach zero. 

To tailor predictions to individual stocks, we applied these modeling techniques separately to each stock in the dataset. A loop was used to iterate through each stock, training and testing the models on its specific data. This approach ensured that the models accounted for the unique patterns and behaviors of each stock. SVR consistently achieved the lowest RMSE across stocks, making it the most reliable model for predicting weekly stock changes. Future work could explore ensemble methods or incorporate additional financial indicators to improve performance further.

# Data

The dataset for this analysis consists of weekly stock performance metrics from the Dow Jones Index, including variables such as opening, closing, high, and low prices, trading volumes, and percentage changes in prices. After importing the data, we conducted a thorough inspection to understand its structure and address missing values. Missing data, particularly in numeric variables like `percent_change_volume_over_last_wk` and `previous_weeks_volume`, was imputed using KNN imputation to maintain data integrity and preserve patterns. Numeric features were normalized and scaled to ensure comparability, which was especially crucial for models like SVR that depend on distance-based calculations. 

To explore potential temporal dependencies, we initially created lagged variables, assuming that previous week changes might have predictive power for the target variable, `percent_change_next_weeks_price`. However, as shown in the lag plot below, there was no significant correlation between the lagged variable (`percent_change_price` of the previous week) and the target variable. The scatterplot shows a nearly flat trend line, indicating that the past week's percentage change provides no meaningful predictive value for the current week's change. Consequently, we excluded the lagged variables from our final models to avoid introducing unnecessary noise. After preprocessing, the data was split into training (Q1) and testing (Q2) sets, maintaining temporal integrity to simulate realistic forecasting scenarios. This preprocessing ensured a solid foundation for our modeling efforts.

Below, the plot illustrates the lack of correlation between the lagged variable and the target, confirming its irrelevance to our predictive modeling: 


```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
pacman::p_load(MASS, tidyverse, here, skimr, rpart, dplyr, VIM, corrplot, car, quantmod, ggplot2, tree, e1071)
select <- dplyr::select
```

```{r, echo=FALSE,results='hide', warning=FALSE, message=FALSE}
raw_index_data <- read.csv(here('case-study-3', 'dow_jones_index.data'))
raw_index_names <- read.csv(here('case-study-3', 'dow_jones_index.names'))
SP500_raw <- read.csv(here('case-study-3', 'SP500.csv'), sep = ',', fileEncoding = 'latin1')

train_data <- subset(raw_index_data, quarter == 1)  # Training data (Q1: Jan-Mar)
test_data <- subset(raw_index_data, quarter == 2)   # Testing data (Q2: Apr-Jun)


selected_vars <- c('date', 'stock', "percent_change_next_weeks_price", "percent_change_price", 
                   "percent_change_volume_over_last_wk", "previous_weeks_volume", 
                   "days_to_next_dividend", "percent_return_next_dividend", 
                   "open", "high", "low", "close")

train_data_filtered <- train_data[,selected_vars]


test_data_filtered <- test_data[,selected_vars]
  


train_data_filtered <- train_data_filtered %>%
  mutate(across(c(open, high, low, close), ~ as.numeric(gsub("[$,]", "", .))))  # Clean and convert

test_data_filtered <- test_data_filtered %>%
  mutate(across(c(open, high, low, close), ~ as.numeric(gsub("[$,]", "", .)))) 


# KNN imputation on the training data
train_data_imputed <- kNN(train_data_filtered, variable = c("percent_change_volume_over_last_wk", "previous_weeks_volume"), 
                          k = 5, imp_var = F)  # Adjust k (number of neighbors) as necessary

# Should return 'FALSE' if no missing values


normalize_min_max <- function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}

train_data_scaled <- train_data_imputed %>%
  mutate(across(where(is.numeric), normalize_min_max))

test_data_scaled <- test_data_filtered %>%
  mutate(across(where(is.numeric), normalize_min_max))


train_data_scaled <- train_data_scaled %>% 
  mutate(date = parse_date_time(date, '%m/%d/%Y'))

test_data_scaled <- test_data_scaled %>% 
  mutate(date = parse_date_time(date, '%m/%d/%Y'))

train_data_scaled %>%
  arrange(date) %>%  
  mutate(
    percent_change_price_lag1 = lag(percent_change_price) 
  ) %>% head()

train_data_scaled <- train_data_scaled %>%
  group_by(stock) %>% 
  arrange(date) %>%  
  mutate(
    percent_change_price_lag1 = lag(percent_change_price, n = 1) 
  ) %>% ungroup()

test_data_scaled <- test_data_scaled %>%
  group_by(stock) %>% 
  arrange(date) %>%  
  mutate(
    percent_change_price_lag1 = lag(percent_change_price, n = 1) 
  ) %>% ungroup()


ggplot(train_data_scaled, aes(x = percent_change_price_lag1, y = percent_change_price)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", color = "blue", se = FALSE) +
  labs(
    title = "Lagged Variable Plot: Percentage Change in Price (t) vs (t-1)",
    x = "Percentage Change in Price (t-1)",
    y = "Percentage Change in Price (t)"
  ) +
  theme_minimal()

```

# Findings

Our analysis assessed the performance of Linear Regression (LM), Decision Trees (DT), and Support Vector Regression (SVR) for predicting weekly stock price changes, with Root Mean Square Error (RMSE) as the evaluation metric. Preprocessing steps, including KNN imputation and normalization, ensured the models were optimized for performance. Among the models, SVR consistently delivered the lowest RMSE, averaging **0.211**, compared to **18.3** for LM and **0.250** for DT, as shown in the bar chart below. This highlights SVR’s superior ability to capture complex, non-linear relationships, making it the most reliable model for stock forecasting.

For individual stocks such as AA, AXP, and BA, SVR demonstrated robust performance, with RMSE values of **0.234**, **0.167**, and **0.250**, respectively. In contrast, LM’s RMSE for these stocks was significantly higher at **18.8**, **16.8**, and **3.21**, while DT showed moderate accuracy with RMSE values of **0.335**, **0.234**, and **0.274**. The bar chart below compares RMSE values across all three models, clearly illustrating SVR’s consistent accuracy.

The second visual, a line graph, provides an analysis of stock performance relative to the S&P 500. This graph plots the Beta coefficient (x-axis), which measures each stock's volatility compared to the market, against performance (y-axis). Stocks on the left represent lower risk (Beta < 1), while those on the right show higher risk (Beta > 1). This risk-performance relationship helps contextualize each stock’s predictive accuracy and market behavior. SVR's ability to accurately forecast stock prices across both low- and high-risk stocks demonstrates its adaptability, even under varying market conditions.

### Visuals:
1. **Bar Chart: RMSE Comparison Across Models**  
   Highlights the predictive accuracy of LM, DT, and SVR for individual stocks.

2. **Line Graph: Stock Performance Relative to S&P 500**  
   Shows the relationship between risk (Beta coefficient) and stock performance, providing insights into market dynamics and risk management.
2. **Bar Graph: Comparison of Actual vs SVR Prediction by Stock**  

These findings affirm SVR as the most effective model for predicting weekly stock price changes, offering both accuracy and adaptability. Future efforts could explore ensemble methods or integrate additional risk indicators for enhanced forecasting.



```{r, echo=FALSE, warning=FALSE, message=FALSE}
train_data_scaled <- train_data_scaled[ , names(train_data_scaled) != 'percent_change_price_lag1']
test_data_scaled <- test_data_scaled[ , names(test_data_scaled) != 'percent_change_price_lag1']

form1 <- percent_change_next_weeks_price ~ .

svr_tune_lists <- list() # initiate models list
best_Params_list <- list() # initiate list of best parameters for SVR for each stock

for (i in c(unique(train_data_scaled$stock))) {
  set.seed(123)
  svr_tune_lists[[i]] <-  tune.svm(form1, data = filter(train_data_scaled, stock == i)[, names(train_data_scaled) != 'stock'],
                                   gamma = seq(.005,.1, by = .005), cost = seq(1, 10, by = 1), scale = T
                                   )
  best_Params_list[[i]] <- svr_tune_lists[[i]]$best.parameters
}


# this is the part to copy for the other models
svr_fit_list <- list()

for (i in c(unique(train_data_scaled$stock))) {
  set.seed(123)
  svr_fit_list[[i]] <-  svm(form1, data = filter(train_data_scaled, stock == i)[, names(train_data_scaled) != 'stock'],
                                   gamma = best_Params_list[[i]]$gamma, cost = best_Params_list[[i]]$cost, scale = T
                                   )
}

newpreds <- list()
for (i in c(unique(train_data_scaled$stock))) {
  newpreds[[i]] <- test_data_scaled %>% filter(stock == i) %>% select(date, stock, percent_change_next_weeks_price) # first model needs this line, all others can skip
  newpreds[[i]]$svr <- predict(svr_fit_list[[i]], filter(test_data_scaled, stock == i)[, names(test_data_scaled) != 'stock'])
}

predsdf <- bind_rows(newpreds, .id = "column_label")

# Defining the formula for LM dynamically to use all existing variables except 'percent_change_next_weeks_price'
lm_formula <- as.formula(paste("percent_change_next_weeks_price ~ ."))

lm_fit_list <- list()

for (i in unique(train_data_scaled$stock)) {
  set.seed(123)
  stock_data <- filter(train_data_scaled, stock == i) %>% select(-stock)
  lm_fit_list[[i]] <- lm(lm_formula, data = stock_data)
}



for (i in unique(test_data_scaled$stock)) {
  newpreds[[i]]$lm_pred <- predict(lm_fit_list[[i]], newdata = filter(test_data_scaled, stock == i))
}

combined_preds_df <- bind_rows(newpreds, .id = "stock")


# Define formula for the decision tree model
tree_formula <- as.formula("percent_change_next_weeks_price ~ .")

# Initialize a list to store the decision tree fits for each stock
tree_fit_list <- list()

# Loop through each unique stock and fit a decision tree model
for (i in unique(test_data_scaled$stock)) {
  set.seed(123)
  tree_fit_list[[i]] <- tree(tree_formula, data = stock_data)
}

# Initialize a list to store predictions
treepreds <- list()

# Loop through each unique stock and get predictions from the decision tree model
for (i in unique(test_data_scaled$stock)) {
  treepreds[[i]] <- filter(test_data_scaled, stock == i)
  newpreds[[i]]$tree_pred <- predict(tree_fit_list[[i]], newdata = treepreds[[i]])
}

combined_preds_df <- bind_rows(newpreds, .id = "stock")



```

```{r, echo=FALSE, warning=FALSE, message=FALSE}

performance_metrics <- combined_preds_df %>%
  group_by(stock) %>%
  summarize(
    RMSE_LM = sqrt(mean((percent_change_next_weeks_price - lm_pred)^2, na.rm = TRUE)),
    RMSE_SVR = sqrt(mean((percent_change_next_weeks_price - svr)^2, na.rm = TRUE)),
    RMSE_Tree = sqrt(mean((percent_change_next_weeks_price - tree_pred)^2, na.rm = TRUE)),
  )

performance_metrics %>% summarize(
  RMSE_LM = mean(RMSE_LM),
  RMSE_SVR = mean(RMSE_SVR),
  RMSE_Tree = mean(RMSE_Tree)
  )

combined_preds_df %>%
  summarize(
    RMSE_LM = sqrt(mean((percent_change_next_weeks_price - lm_pred)^2, na.rm = TRUE)),
    RMSE_SVR = sqrt(mean((percent_change_next_weeks_price - svr)^2, na.rm = TRUE)),
    RMSE_Tree = sqrt(mean((percent_change_next_weeks_price - tree_pred)^2, na.rm = TRUE))
  )

ggplot(combined_preds_df, aes(x = percent_change_next_weeks_price)) +
  geom_point(aes(y = lm_pred, color = "LM"), alpha = 0.5) +
  geom_point(aes(y = svr, color = "SVR"), alpha = 0.5) +
  geom_point(aes(y = tree_pred, color = "Tree"), alpha = 0.5) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  labs(
    title = "Actual vs Predicted Values for LM, SVR, and Decision Trees",
    x = "Actual Percent Change Next Week's Price",
    y = "Predicted Percent Change Next Week's Price"
  ) +
  facet_wrap(~ stock) +
  scale_color_manual(name = "Model", values = c("LM" = "blue", "SVR" = "red", "Tree" = 'green')) +
  theme_minimal()

SP500 <- SP500_raw %>% mutate(
  Date = parse_date_time(Date, '%d-%b-%y'),
  Date = Date + days(4)
) %>% mutate_at(
  2:7, parse_number
) %>% mutate(
  percent_change = (Close. - Open)/Open
) %>% select(Date, percent_change)

train_data_filtered %>% mutate(pct = (close-open)/open) %>% select(pct, percent_change_price) %>% head()

risk_data <- raw_index_data %>% select(date, stock, percent_change_price) %>% 
  mutate(
    date = parse_date_time(date, '%m/%d/%Y'),
    percent_change_price = percent_change_price/100
  )

rd_joined <- left_join(risk_data, SP500, join_by(date == Date))

risk_fit_list <- list()

for (i in unique(rd_joined$stock)) {
  set.seed(123)
  stock_risk <- filter(rd_joined, stock == i)
  risk_fit_list[[i]] <- lm(percent_change_price ~ percent_change, data = stock_risk)
}


stock_betas <- list()

for (i in unique(rd_joined$stock)) {
  stock_betas[[i]] <- summary(risk_fit_list[[i]])$coefficients[2, 1] %>% as.data.frame()
}

betas_df <- bind_rows(stock_betas, .id = 'stock')
names(betas_df) <- c('stock', 'betas')

Jul1_preds <- combined_preds_df %>% filter(date == max(date)) %>% select(stock, percent_change_next_weeks_price, svr)

risk_pred <- Jul1_preds %>% left_join(betas_df, join_by(stock))


ggplot(risk_pred, aes(x = betas, y = svr, label = stock)) +
  geom_point(color = "blue", alpha = 0.7) +
  geom_text(vjust = -1, hjust = 1, size = 3) +
  labs(
    title = "Risk-Return Trade-Off by Stock",
    x = "Betas",
    y = "Predicted Percent Change for Next Week"
  ) +
  theme_minimal()


ggplot(risk_pred, aes(x = stock)) +
  geom_bar(aes(y = percent_change_next_weeks_price, fill = "Actual"), stat = "identity", position = "dodge") +
  geom_point(aes(y = svr, fill = "SVR \nPrediction"), shape = '_', size = 7, color = 'orange') +
  labs(
    title = "Comparison of Actual Percent Change and SVR by Stock",
    x = "Stock",
    y = "Percent Change (normalized values)"
  ) +
  scale_fill_manual(values = c("Actual" = "dodgerblue", "SVR \nPrediction" = "orange")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


# Conclusion


In conclusion, the study demonstrated that Support Vector Regression (SVR) is the most effective model for predicting weekly stock price changes, consistently outperforming Linear Regression and Decision Trees in terms of RMSE. This result underscores the importance of selecting models capable of capturing complex, non-linear relationships in financial data. The preprocessing steps, including normalization and KNN imputation, ensured the models operated on high-quality data, contributing to the reliability of the findings. While the SVR model showed strong predictive performance, future improvements could involve exploring ensemble techniques and integrating additional indicators such as market sentiment or macroeconomic variables. These enhancements could further refine the models’ predictive capabilities and provide deeper insights into stock market behavior, aiding investors in making informed, data-driven decisions.

