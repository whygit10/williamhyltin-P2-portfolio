---
title: "DA 6813 Case Study 1 "
author: "Will Hyltin, Holly Milazzo and Tim Harrison"
date: today
format: 
  html:
    code-fold: true # Folds code by default
    number-sections: true # Numbered sections
    df-print: paged # Nice table format
    fig-align: center # Centers figures
    fig-width: 6 # Adjust figure size
    fig-height: 4
    reference-location: section # Valid value for citation references
    page-layout: article
---

```{r setup, echo=FALSE}
pacman::p_load(MASS, tidyverse, here, car, corrplot, skimr, caret, ggplot2, dplyr, tidyr, ROCR,knitr)
df1 <- read.csv(here('case-study-1','bank-additional.csv'), sep = ';')
df2 <- df1 %>% mutate_if(is.character, as.factor)
df3 <- df2 %>% mutate(
  pcontact = ifelse(pdays == 999, 0, 1),
  y = ifelse(y == 'yes',1,0)
) %>% select(!pdays)


```

# Executive Summary

```{=html}
<!-- 
Purpose: Provide a concise overview of the key findings and results of the analysis.
Instructions: Summarize the performance of the models (e.g., random forest, decision tree, logistic regression). Highlight the best-performing model and key insights regarding customer acquisition. Avoid technical details, focusing on high-level conclusions that decision-makers would care about.
-->
```


This study aimed to develop a predictive model to determine whether clients of a Portuguese banking institution would subscribe to a term deposit following a marketing campaign. The analysis focused on a dataset containing client demographics, financial indicators, and marketing campaign details. Key variables such as age, contact type, month of the campaign, number of previous contacts, employment rate, and previous client contacts were found to influence the likelihood of subscription.

Due to the unbalanced nature of our response variable, a balanced sample was taken so the model would not favor prediction for those who did not subscribe versus those that did. Then, a logistic regression model was built using backward stepwise selection based on the Akaike Information Criterion (AIC). Initially, the model had high specificity (86.36%), meaning it effectively identified clients that did not subscribe. However, despite balancing train and test sets, it underperformed in identifying clients who did subscribe, as reflected by its lower sensitivity (56.99%).

To further improve the model's overall performance, an optimal decision threshold was identified, balancing sensitivity and specificity. After optimization, the model achieved a balanced accuracy of 73.48%, with both sensitivity and specificity improving to 73.12% and 73.86%, respectively. This adjustment enhanced the model's ability to accurately classify both subscribing and non-subscribing clients.

The results provide actionable insights for the bank, enabling it to more effectively target clients and optimize marketing resources. The findings suggest that further improvements, such as testing alternative models or incorporating more detailed features, could yield even higher predictive performance.

# Problem Statement

```{=html}
<!-- 
Purpose: Explain the problem that the study aims to solve.
Instructions: Clearly define the task at hand, which in this case is predicting customer acquisition. Outline the objectives and what solving this problem would mean for the company.
-->
```
The task of this case study is to develop a predictive model to classify whether clients of a Portuguese banking institution will subscribe to a term deposit following a direct marketing campaign. The campaigns were based on phone calls, and often, multiple contacts were made to the same client to assess if they would subscribe ('yes') or not ('no'). The goal is to accurately predict the likelihood of a client subscribing to a term deposit based on various input variables, including demographic, social, and economic indicators, as well as information from previous marketing campaigns.

Key variables influencing the prediction include the client's age, job type, marital status, education, and financial status (e.g., default history, housing loan, and personal loan). Additionally, variables related to the marketing campaign, such as the type of contact, day, and month of the last contact, and previous campaign outcomes, are also critical in determining the client’s response. Social and economic context attributes, such as the employment variation rate and consumer confidence index, are included to enhance the model's predictive power.

The primary objective is to build a classification model that can accurately predict whether a client will subscribe to a term deposit. This will allow the bank to target its marketing efforts more effectively, optimizing resource allocation, and improving conversion rates.

# Methodology

```{=html}
<!-- 
Purpose: Describe the methods and processes used to conduct the analysis.
Instructions: Detail the models used and the reasoning behind them. Include specifics such as hyperparameter tuning, data splitting, and assumptions of each model.
-->
```


The analysis began with data preparation, where the dataset of 21 variables, both categorical and numeric, was cleaned and transformed. Categorical variables were converted to factors for proper handling in models, and the target variable, `y`, was transformed into a binary indicator, where 1 indicated a client subscribed to a term deposit and 0 indicated otherwise. The `pdays` variable, which represented the number of days since a previous contact, was recoded into a binary indicator named `pcontact` to simplify the analysis.

Exploratory data analysis (EDA) was conducted to explore the distribution and relationships within the data. Box plots were generated to visualize the distribution of numeric variables based on the target outcome, and bar plots were used to explore the frequency distribution of categorical variables. Additionally, a correlation matrix was constructed to examine the relationships among numeric variables and to identify potential multicollinearity issues.

The dataset was then split into a training set (80%) and a test set (20%) to ensure model evaluation was conducted on unseen data. To address class imbalance, as there were significantly more clients who did not subscribe to the term deposit, resampling techniques were applied to create a balanced dataset for training. This was done by narrowing down to all responses where a bank customer subscribed and an equal number of those who did not subscribe before performing the train and test split.

Logistic regression was selected as the primary modeling technique. A stepwise backward selection method, based on the Akaike Information Criterion (AIC), was used to remove insignificant variables and select the most parsimonious model. To mitigate multicollinearity, variables with high variance inflation factor (VIF) values were removed. 

The model was evaluated using metrics such as accuracy, sensitivity, and specificity, and the results were summarized in a confusion matrix. Given that class imbalance persisted, even after balancing the data, an optimal cutoff threshold for classifying clients was determined by balancing sensitivity and specificity. This threshold optimization helped improve the performance of the logistic regression model by identifying the point where sensitivity and specificity converged. 



# Data

```{=html}
<!-- 
Purpose: Explain the data used in the analysis and any preprocessing steps.
Instructions: Provide an overview of the dataset, variables, and any cleaning steps or transformations made. Mention variables used or excluded and why.
-->
```
The dataset contains 4,119 rows and 21 variables. The variables are split between 11 categorical (character type) and 10 numeric variables. In preparation for analysis, categorical variables were converted into factors to ensure proper handling in models. The target variable, y, was converted into a binary outcome where "yes" was mapped to 1, indicating that the client subscribed to a term deposit, and "no" was mapped to 0.

```{r, echo=FALSE}
skim(df3)
```

During the exploratory data analysis (EDA), various visualizations were utilized to examine the distributions and relationships within the dataset. Box plots were used to display the distribution of numeric variables such as **age**, **campaign**, **emp.var.rate**, **cons.price.idx**, **cons.conf.idx**, **euribor3m**, and **nr.employed**, stratified by whether or not the client subscribed to a deposit. These visualizations helped identify differences in the distributions between clients who subscribed and those who did not.

Bar plots were also used to explore the distribution of categorical variables like **job**, **marital status**, **education**, **default**, **housing**, **loan**, **contact**, **month**, **day_of_week**, and **poutcome**. These plots illustrated the relative frequencies of each category concerning the target outcome, shedding light on which factors might be more indicative of a client’s decision to subscribe.

Regarding the **pdays** variable, a value of 999 indicated that a client had not been previously contacted, while any other number signified prior contact. To simplify the analysis, this variable was transformed into a binary indicator, where "1" denotes previous contact and "0" indicates no prior contact.

Finally, to explore relationships among numeric variables, a correlation matrix was generated. This matrix was visualized using a heatmap to provide a clear representation of the strength and direction of correlations between variables.

```{r,echo=FALSE}


# Transforming the dataframe to long format
df_long <- df3 %>%
  pivot_longer(cols = c(age, campaign, emp.var.rate, cons.price.idx, cons.conf.idx, euribor3m, nr.employed), 
               names_to = "variable", values_to = "value")

# Creating the boxplots for all variables
ggplot(df_long, aes(x = as.factor(y), y = value)) +
  geom_boxplot() +
  facet_wrap(~variable, scales = "free") +
  labs(x = "y", y = "Value") +
  theme_minimal()


# Convert 'previous' and 'pcontact' to factors
dflong2 <- df3 %>% mutate(
  previous = as.factor(previous),
  pcontact = as.factor(pcontact)
)

# Transforming the dataframe to long format
df_long2 <- dflong2 %>%
  pivot_longer(cols = c(job, marital, education, default, housing, loan, contact, month, day_of_week, poutcome, previous, pcontact),
               names_to = "variable", values_to = "value")

# Creating bar plots for all categorical variables
ggplot(df_long2, aes(fill = as.factor(y), x = value)) +
  geom_bar(position = "dodge") +
  facet_wrap(~variable, scales = "free_x", nrow = 3) +  # Set nrow for larger facet grid
  labs(x = "Variable", y = "Count", fill = "y") +
  ylim(0, 4000) +  # Set y-axis limits from 0 to 4000
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 8),  # Adjust text angle and size
    strip.text = element_text(size = 10)  # Increase facet label size
  )

cor1 <- df3 %>% select_if(is.numeric) %>% cor()
corrplot(cor1)


```

# Findings

The logistic regression model was built using a backward stepwise elimination process based on the Akaike Information Criterion (AIC). During each step, insignificant variables such as job, day_of_week, education, marital status, and others were removed to improve model parsimony and fit. The final model included age, contact, month, campaign, nr.employed, and pcontact as the key predictors.

Two sets of results were generated to evaluate the performance of the model—one based on the initial logistic regression with a non-optimal threshold and the other with an optimized threshold for better classification performance.

For the **non-optimal threshold**, the confusion matrix showed an accuracy of 71.27%, with a specificity of 86.36% and a sensitivity of 56.99%. The model had higher specificity, meaning it was better at correctly identifying clients who did not subscribe, but it performed less well in identifying those who did.

After **threshold optimization**, the model's performance improved. The confusion matrix for the optimized model yielded an accuracy of 73.48%, with more balanced specificity (73.86%) and sensitivity (73.12%). This optimization process allowed for better classification of both subscribing and non-subscribing clients by adjusting the decision threshold to balance the trade-off between specificity. and sensitivity

Overall, the findings indicate that the threshold adjustment improved the model’s ability to predict both positive and negative outcomes more evenly. This highlights the importance of optimizing decision thresholds, particularly in imbalanced datasets like this one. Interestingly, this issue was still encountered despite balancing the initial audience data based on the response value, suggesting that an imbalance in the predictors may also influence a binary classification model's performance. 

```{=html}
<!-- 
Purpose: Present the results of the analysis.
Instructions: Report accuracy rates and compare the performance of models. Discuss significant variables or interactions discovered.
-->
```
```{r, echo=FALSE}
df4 <- df3 %>% dplyr::select(!duration)
# Split data into training and testing samples
# Setting seed locks the random number generator. 
set.seed(321)
trn_part <- sample(nrow(df4),0.8*nrow(df4),replace = F) # Setting training sample to be 80% of the data
dftrain <- df4[trn_part,]
dftest <- df4[-trn_part,]

## Resample with more balanced data 
df_sub = df4 %>% filter(y == 1)
df_no_sub = df4 %>% filter(y == 0)
sample_no_sub = sample_n(df_no_sub, nrow(df_sub))
df_bal = rbind(sample_no_sub,df_sub)

# Split data into training and testing balanced samples
set.seed(321)
tr_ind_bal <- sample(nrow(df_bal), 0.8 * nrow(df_bal), replace = FALSE) # Setting training sample to be 80% of the balanced data
dftrain_bal <- df_bal[tr_ind_bal, ]
dftest_bal <- df_bal[-tr_ind_bal, ]


# Stepwise backward elimination (suppress intermediate output)
m7.log <- step(glm(as.factor(y) ~ . - loan - emp.var.rate - euribor3m, 
                   data = dftrain_bal, family = binomial), 
               direction = "backward", trace = 0)

# Predictions using the final model
predprob_final <- predict(m7.log, newdata = dftest_bal, type = "response")
pr_class_final <- ifelse(predprob_final > 0.5, 1, 0)  # You can adjust the threshold as needed

predprob2_log_bal <- predict(m7.log, newdata = dftest_bal, type = "response")  # Predict probabilities for the test set
predclass2_log_bal <- ifelse(predprob2_log_bal >= 0.5, 1, 0)  # Classify based on the threshold

# Confusion matrix for the final model
conf_matrix <- caret::confusionMatrix(as.factor(pr_class_final), as.factor(dftest_bal$y), positive = '1')

# Extract confusion matrix, accuracy, sensitivity, and specificity
cm1_table <- as.data.frame.matrix(conf_matrix$table)
accuracy <- round(conf_matrix$overall['Accuracy'], 4)
sensitivity <- round(conf_matrix$byClass['Sensitivity'], 4)
specificity <- round(conf_matrix$byClass['Specificity'], 4)

# Create a data frame for the results
results1_df <- data.frame(
  Value = c(accuracy, sensitivity, specificity)
)

# Display the AIC at each step
kable(m7.log$anova, format = "pipe", align = "c", caption = "AIC at Each Step")

# Print Confusion Matrix and Model Results
kable(cm1_table, format = "pipe", align = "c", caption = "Confusion Matrix Non-Optimal Value")


kable(results1_df, format = "pipe", align = "c", col.names = c("Metric", "Value"), caption = "Model Results Non-Optimal Value")

```

```{r, echo=FALSE}
pred_bal <- prediction(predprob2_log_bal,dftest_bal$y) #Predicted Probability and True Classification

auc_bal <- round(as.numeric(performance(pred_bal, measure = "auc")@y.values),3)

# computing threshold for cutoff to best trade off sensitivity and specificity, unbalanced first
#first sensitivity
plot(unlist(performance(pred_bal, "sens")@x.values), unlist(performance(pred_bal, "sens")@y.values), 
     type="l", lwd=2, 
     ylab="Sensitivity", xlab="Cutoff", main = paste("Maximized Cutoff\n","AUC: ",auc_bal))

par(new=TRUE) # plot another line in same plot

#second specificity
plot(unlist(performance(pred_bal, "spec")@x.values), unlist(performance(pred_bal, "spec")@y.values), 
     type="l", lwd=2, col='red', ylab="", xlab="")
axis(4, at=seq(0,1,0.2)) #specificity axis labels
mtext("Specificity",side=4, col='red')

#find where the lines intersect
min.diff_bal <-which.min(abs(unlist(performance(pred_bal, "sens")@y.values) - unlist(performance(pred_bal, "spec")@y.values)))
min.x_bal<-unlist(performance(pred_bal, "sens")@x.values)[min.diff_bal]
min.y_bal<-unlist(performance(pred_bal, "spec")@y.values)[min.diff_bal]
optimal_bal <-min.x_bal #this is the optimal points to best trade off sensitivity and specificity

abline(h = min.y_bal, lty = 3)
abline(v = min.x_bal, lty = 3)
text(min.x_bal,0,paste("optimal threshold=",round(optimal_bal,2)), pos = 3)

# Use the optimal cutoff to classify
pr_class_bal = ifelse(predprob2_log_bal > optimal_bal, 1, 0)

# Store the confusion matrix result in a variable without printing
conf_matrix <- caret::confusionMatrix(as.factor(pr_class_bal), as.factor(dftest_bal$y), positive = '1')

```

```{r, echo=FALSE}

# Calculate the confusion matrix
conf_matrix <- caret::confusionMatrix(as.factor(pr_class_bal), as.factor(dftest_bal$y), positive = '1')

# Extract the confusion matrix, accuracy, sensitivity, and specificity
cm_table <- as.data.frame.matrix(conf_matrix$table)  # Convert confusion matrix to a data frame
accuracy <- conf_matrix$overall['Accuracy']
sensitivity <- conf_matrix$byClass['Sensitivity']
specificity <- conf_matrix$byClass['Specificity']

# Create a data frame for the results
results_df <- data.frame(
  
  Value = c(round(accuracy, 4), round(sensitivity, 4), round(specificity, 4))
)

# Print the Confusion Matrix

kable(cm_table, format = "pipe", align = "c", caption = "Confusion Matrix Optimal Value")

# Print the table with a title

kable(results_df, format = "pipe", align = "c", col.names = c("Metric", "Value"), caption = "Model Results Optimal Value")

 # Show the final model formula

final_formula <- formula(m7.log)
print(final_formula)

```

# Conclusion

The analysis successfully developed a logistic regression model to predict whether clients would subscribe to a term deposit following a marketing campaign. Through data preparation, exploratory analysis, and model building, key predictors such as age, contact, month, campaign, employment status (nr.employed), and previous contact (pcontact) were identified as significant factors influencing client subscription decisions. 

The initial model had a higher specificity but lower sensitivity, meaning it was more effective at identifying clients who did not subscribe but less so for those who did. After optimizing the decision threshold, the model achieved a more balanced performance, with improved accuracy and sensitivity. This highlights the value of threshold adjustment in classification problems, particularly when dealing with imbalanced datasets.

In conclusion, the model offers actionable insights for the bank to more effectively target potential customers, allowing for better allocation of marketing resources and improved conversion rates. Further enhancements, such as testing additional models or incorporating more complex feature engineering, could further improve predictive performance.
